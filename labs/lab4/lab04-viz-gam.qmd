---
title: "Lab 04 - Data Visualization and GAMs"
format:
  html:
    embed-resources: true
jupyter: python3
---

```{python}
#| label: setup
#| message: false
#| warning: false
import pandas as pd
import numpy as np
from plotnine import *
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
from pygam import LinearGAM, s
import statsmodels.api as sm
from folium.plugins import MarkerCluster
```

# Learning Goals

- Read in and prepare the meteorological dataset
- Use `pd.merge()` to join two datasets
- Deal with missings and impute data
- Create several graphs with different `geoms` in `plotnine`
- Create a facet graph
- Conduct customizations of the graphs
- Fit smooth regression models using `pygam` and compare to a linear regression model

# Lab Description

We will work with the meteorological data from last week's lab.

**The objective of the lab is to examine the association between weather variables in the US, practice data visualization, and fit smooth regression models.**


### 1. Read in the data

First download and then read in with pandas:

```{python}
url = "https://raw.githubusercontent.com/JSC370/JSC370-2026/main/data/met_all_2025.gz"
met = pd.read_csv(url, compression="gzip")
```

### 2. Prepare the data: some wrangling

- From last week: remove temperatures less than -20C and change 999.9 to NaN.
- Generate a date variable using `pd.to_datetime()`.
- Using date filtering, keep the observations of the first week of July 2025.
- Compute the mean by station of the variables `temp`, `rh`, `wind_sp`, `vis_dist`, `dew_point`, `lat`, `lon`, and `elev`.
- Create a region variable for NW, SW, NE, SE based on lon = -98.00 and lat = 39.71 degrees.
- Create a categorical variable for elevation (low: < 252m, high: >= 252m)

```{python}
# Replace 999.9 with NaN and filter temps > -20
met.loc[met['temp'] == 999.9, 'temp'] = np.nan
met = met[met['temp'] > -20].copy()

# Create date variable
met['date'] = pd.to_datetime(
    met[['year', 'month', 'day', 'hour']])

# Create region variable using np.select
met['region'] = (
    np.select(
        [
            (met['lon'] < -98) & (met['lat'] >= 39.71),
            (met['lon'] >= -98) & (met['lat'] >= 39.71),
            (met['lon'] < -98) & (met['lat'] < 39.71),
        ],
        ['NW', 'NE', 'SW'],
        default='SE'
    )
)

# Create elevation category
met['elev_high_low'] = np.select(
    [met['elev'] >= 252],
    ['high'],
    default='low'
)

display(met.head())
```



### 3. Use `geom_violin` to examine `dew_point` for low and high elevations by region

Use `geom_violin` and subset the data to the first two weeks in July.

- Subset to the first two weeks in July
- Use facets
- Summarize below

```{python}
# Subset to first two weeks of July
met_july = met[(met['date'] >= '2025-07-01') & (met['date'] < '2025-07-15')].copy()

# Create violin plot with facets
(ggplot(met_july,
        aes(x='elev_high_low', y='dew_point', fill='elev_high_low')) +
  geom_violin() +
  facet_wrap('~region') +
  labs(x='Elevation Category', y='Dew Point Temperature',
       title='Dew Point by Elevation and Region (July 1 - 14)') +
  theme_minimal())

```

Summary:

- We can see that the dew point has similar distribution between High elevation and Low elevation for region NE and SE. Further, we can see that dew point in SE is tend to more concentrated around mean, which mean there is less variation

- We can see that the NW and SW has large variation in dew point on high elevation. Even more interesting, we can see that Low Elevation in SW has 2 substantially different peak.

### 4. Use `geom_bar` to create barplots of the proportion of weather stations by elevation category colored by region

- Use the subset data from \#3, the first two weeks of July
- Create nice labels on axes and add a title
- Try a second plot with counts and `dodge` positioning
- Summarize below

```{python}
# Proportion barplot (position='fill')
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='fill') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Proportion of Stations',
       title='Proportion of Weather Stations by Elevation and Region') +
  theme_minimal())
```

```{python}
# Count barplot with dodge positioning
(ggplot(met_july,
        aes(x='elev_high_low', fill='region')) +
  geom_bar(position='dodge') +
  scale_fill_brewer(type='qual', palette='Set2') +
  labs(x='Elevation Category', y='Number of Stations',
       title='Weather Stations by Elevation and Region') +
  theme_minimal())

```

Summary:

- From the first graph, we can see that SE dominates Low Elevation in term of number of weather stations. We can also see that there is relatively small number of weather stations in low elevation from SW and NW

- In the high elevation, we can see that the proportion is somehow balanced with slightly dominated by NE region. 

- Second graph emphasize these findings further. It shows how SE has very large number of weather stations in low elevation. Besides, it also shows how turns out, the number of weather stations high elevation from NE is nearly doubled other region.


### 5. Use `stat_summary` to examine mean dew point by region with standard deviation error bars

- Use `stat_summary` with appropriate functions for mean and standard deviation
- Add error bars using another layer of `stat_summary` with `geom = "errorbar"`
- Use `coord_flip`
- Add labels and a title
- Summarize below

```{python}
# Use stat_summary with fun_y, fun_ymin, fun_ymax
# Hint: fun_ymin=lambda x: np.mean(x) - np.std(x)

(ggplot(met_july, aes(x='region', y='dew_point')) +
  stat_summary(fun_y=lambda x: np.mean(x),
               fun_ymin=lambda x: np.mean(x) - np.std(x),
               fun_ymax=lambda x: np.mean(x) + np.std(x),
               geom='errorbar') +
  coord_flip() +
  labs(y='Dew Point Temperature', x='Region',
       title='Mean and Standard Deviation Dew Point Temperature by Geographic Region') +
  theme_minimal())
```

Summary:

- Similar with our findings from previous graph, we can see that the standard deviation of dew point temperature for NE and SE is relatively small while for NW and SW is relatively bigger. 

- In here, we can also see that there is difference of average dew point temperature across regions. 


### 6. Smooth Regression with GAMs

Let's practice running regression models with smooth functions on X. We use the `statsmodels` OLS for linear models and `pygam` package and `LinearGAM` function to do this.

- Use the subsetted data. First remove NaN before fitting
- Fit both a linear model with `sm.OLS` and a spline model (use `LinearGAM()` with `s()` for a smooth term on wind_sp and temp).
- For the spline model try `n_splines` = 20
- Summarize and plot the results from the models.

```{python}
# Data prep
# Remove NaN values before fitting
met_clean = met_july.dropna(subset=['wind_sp', 'temp', 'dew_point'])

X = met_clean[['wind_sp', 'temp']].values
y = met_clean['dew_point'].values
```

- Now fit linear model with sm.OLS

```{python}
# Don't forget to add a constant
X_const = sm.add_constant(X)

linear_mod = sm.OLS(y, X_const).fit()
print("Linear Model:")
print(linear_mod.summary())
```

Summary:

- Adjusted R2: 0.115, quite small if our purpose if prediction

- We can see that the p-values for both x1 (Wind Speed) and x2 (Temperature) are nearly 0. It means that both beta coefficients are significant. 


```{python}
# GAM spline model
# Use LinearGAM with s() for smooth terms
# s(0) refers to first column, s(1) to second column

gam_mod = LinearGAM(
    s(0, n_splines=20) +
    s(1, n_splines=20)).fit(X, y)
print("\nSmooth Spline Model:")
print(gam_mod.summary())
```

Summary:

- Pseudo R-squared: 0.2868, nearly doubled adjusted R2 from OLS

- EDoF: Wind Speed = 13.5   |  Temperature = 16.9

- We can see that the p - values for wind speed and temperature are nearly zero. It means that the smooths are significant for both predictors.


```{python}
#| fig-align: center
# Plot partial dependence curves for each predictor

# define the figure size
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# define the variables and colors
spec = [
    (0, 0, "Wind Speed",  "blue", "Effect of Wind Speed"),
    (1, 1, "Temperature", "red",  "Effect of Temperature"),
]

# loop over smooth variables
for ax, (term, xcol, xlabel, color, title) in zip(axes, spec):
    XX = gam_mod.generate_X_grid(term=term)
    x = XX[:, xcol]
    pd_effect = gam_mod.partial_dependence(term=term, X=XX)
    _, ci = gam_mod.partial_dependence(term=term, X=XX, width=0.95)

    ax.plot(x, pd_effect, color=color, lw=2)
    ax.plot(x, ci, color=color, ls="--", lw=1)
    ax.set(xlabel=xlabel, ylabel="Partial Effect on Dew Point", title=title)

plt.tight_layout()
plt.show()
```

Summary:

- For Wind Speed, we can see that the partial effect on Dew Point is substantially different from linear. Altough the 95% CI of the partial effect is quite big, we can clearly see that it's still non-linear. Therefore, we can say that the smooth in Wind Speed capture meaningful non-linearity

- For Temperature, we can see that the partial effect on Dew Point is quite different than linear. Besides, the 95% CI of the partial effect is quite narrow, suggesting that the true partial effect is not really far from fitted partial effect. Therefore, we can also say that the smooth in Temperature capture meaningful non-linearity

